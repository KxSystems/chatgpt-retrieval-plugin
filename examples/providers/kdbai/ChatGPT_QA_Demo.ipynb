{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDB.AI for Q&A with ChatGPT Retrieval Plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example will demonstrate how to use the ChatGPT Retrieval Plugin to embed and store data in KDB.AI, as well as to query the embedded data. The plugin enables ChatGPT large language models, such as GPT-3.5, to be used for querying data that it wasn't trained on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the ChatGPT Retrieval Plugin work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kdbai-chatgpt-overview](kdbai-chatgpt-overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagram above provides a high-level overview of the system, and explains how ChatGPT, the Retrieval Plugin, and KDB.AI all interact with one another. The system can be broken down into two main sub-systems: upserting (shown in red) and querying (shown in blue).\n",
    "\n",
    "\n",
    "### Upserting\n",
    "\n",
    "Upserting is the process of taking our own dataset and uploading it to our vector database. In order to upsert data, we must pre-process it to remove any part we do not want to store in the database, change the format to a dictionary, and divide it into batches. When we call  `/upsert`, each batch of data is embedded using an OpenAI LLM (Large Language Model), to generate a vector embedding for similarity search. The data and its embedding are then inserted into a KDB.AI table.\n",
    "\n",
    "\n",
    "### Querying\n",
    "\n",
    "Querying involves taking an input query, or question, transforming it into an embedded vector, and running similarity search in the vector database to find its nearest neighbours - data with closest relevancy to the query. When we call `/query`,  the input query is embedded with the same OpenAI LLM used for upserting, to generate a query vector. A similarity search algorithm running within KDB.AI will return the N closest matches with highest relevancy to the query. This \"context\" is then sent back to ChatGPT via the Retrieval Plugin. Finally, using this contextual information, ChatGPT outputs a human-like response to the query.\n",
    "\n",
    "Having an external source of data greatly increases the applicability of ChatGPT to different tasks. For example: GPT-3.5 can only answer questions with information it has seen during training, which is capped at 2021.. Therefore, if you asked it who the 2023 UK Prime Minister is, the model does not have the necessary information. However, if you were to download a dataset of political data up to the present day, ChatGPT would be able to use this data to answer the question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Python 3\n",
    "- Pip\n",
    "- Git\n",
    "\n",
    "### Install the KDB.AI ChatGPT Retrieval Plugin server app\n",
    "\n",
    "```\n",
    "git clone https://github.com/KxSystems/chatgpt-retrieval-plugin -b KDB.AI\n",
    "cd chatgpt-retrieval-plugin\n",
    "pip install poetry\n",
    "poetry install\n",
    "```\n",
    "\n",
    "### Run the KDB.AI ChatGPT Retrieval Plugin server app\n",
    "\n",
    "```\n",
    "export BEARER_TOKEN='<BEARER TOKEN>'  # you can create your own bearer token on auth0.com\n",
    "export DATASTORE=kdbai\n",
    "export KDBAI_ENDPOINT='<KDB.AI ENDPOINT>'\n",
    "export KDBAI_API_KEY='<KDB.AI API KEY>'\n",
    "export OPENAI_API_KEY='<OPENAI API KEY>'  # You can get a free API key on https://platform.openai.com\n",
    "\n",
    "poetry run start\n",
    "```\n",
    "\n",
    "### Install a separate Jupyter environment to run this notebook\n",
    "\n",
    "```\n",
    "pip install datasets jupyter openai tqdm\n",
    "```\n",
    "\n",
    "### Run Jupyter\n",
    "\n",
    "```\n",
    "export BEARER_TOKEN='<BEARER TOKEN>'  # Same bearer token as above\n",
    "export OPENAI_API_KEY='<OPENAI API KEY>'\n",
    "\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "Then open this notebook in Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import random\n",
    "\n",
    "from datasets import load_dataset\n",
    "import openai\n",
    "import requests\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEARER_TOKEN = os.environ.get(\"BEARER_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset from Hugging Face\n",
    "\n",
    "The Adversarial_QA dataset is chosen for this demonstration. It consists of questions that current state-of-the-art models find challenging, paired with contextual data that can be used to formulate an answer. Some of these questions have very poor grammar (\"What sare the benifts of the blood brain barrir?\"), and others are purposefully vague (\"What is at the highest level?\"), as shown in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique contexts: 2648\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7ba1e8f4261d3170fcf42e84a81dd749116fae95</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Another approach to brain function is to exami...</td>\n",
       "      <td>What sare the benifts of the blood brain barrir?</td>\n",
       "      <td>{'text': ['isolated from the bloodstream'], 'a...</td>\n",
       "      <td>{'split': 'train', 'model_in_the_loop': 'Combi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>936a8460bfffe437b54cf3ec1e825a3b7b5627a1</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Motor systems are areas of the brain that are ...</td>\n",
       "      <td>What do you think with?</td>\n",
       "      <td>{'text': ['brain'], 'answer_start': [467]}</td>\n",
       "      <td>{'split': 'train', 'model_in_the_loop': 'Combi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>e40737d487964dbcd26a223f2799cf56390a98a8</td>\n",
       "      <td>Brain</td>\n",
       "      <td>The brain is an organ that serves as the cente...</td>\n",
       "      <td>How are neurons connected?</td>\n",
       "      <td>{'text': ['synapses'], 'answer_start': [602]}</td>\n",
       "      <td>{'split': 'train', 'model_in_the_loop': 'Combi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>a0f8e785a10f6e21e24207d24ba2823162383062</td>\n",
       "      <td>Brain</td>\n",
       "      <td>The SCN projects to a set of areas in the hypo...</td>\n",
       "      <td>The body's central biological clock is contain...</td>\n",
       "      <td>{'text': ['SCN'], 'answer_start': [4]}</td>\n",
       "      <td>{'split': 'train', 'model_in_the_loop': 'Combi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>6d753d4a8878b5f5bc496d9a369b8c0b212079a0</td>\n",
       "      <td>Brain</td>\n",
       "      <td>The brain contains several motor areas that pr...</td>\n",
       "      <td>What is at the highest level?</td>\n",
       "      <td>{'text': ['the primary motor cortex'], 'answer...</td>\n",
       "      <td>{'split': 'train', 'model_in_the_loop': 'Combi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          id  title  \\\n",
       "0   7ba1e8f4261d3170fcf42e84a81dd749116fae95  Brain   \n",
       "12  936a8460bfffe437b54cf3ec1e825a3b7b5627a1  Brain   \n",
       "24  e40737d487964dbcd26a223f2799cf56390a98a8  Brain   \n",
       "37  a0f8e785a10f6e21e24207d24ba2823162383062  Brain   \n",
       "53  6d753d4a8878b5f5bc496d9a369b8c0b212079a0  Brain   \n",
       "\n",
       "                                              context  \\\n",
       "0   Another approach to brain function is to exami...   \n",
       "12  Motor systems are areas of the brain that are ...   \n",
       "24  The brain is an organ that serves as the cente...   \n",
       "37  The SCN projects to a set of areas in the hypo...   \n",
       "53  The brain contains several motor areas that pr...   \n",
       "\n",
       "                                             question  \\\n",
       "0    What sare the benifts of the blood brain barrir?   \n",
       "12                            What do you think with?   \n",
       "24                         How are neurons connected?   \n",
       "37  The body's central biological clock is contain...   \n",
       "53                      What is at the highest level?   \n",
       "\n",
       "                                              answers  \\\n",
       "0   {'text': ['isolated from the bloodstream'], 'a...   \n",
       "12         {'text': ['brain'], 'answer_start': [467]}   \n",
       "24      {'text': ['synapses'], 'answer_start': [602]}   \n",
       "37             {'text': ['SCN'], 'answer_start': [4]}   \n",
       "53  {'text': ['the primary motor cortex'], 'answer...   \n",
       "\n",
       "                                             metadata  \n",
       "0   {'split': 'train', 'model_in_the_loop': 'Combi...  \n",
       "12  {'split': 'train', 'model_in_the_loop': 'Combi...  \n",
       "24  {'split': 'train', 'model_in_the_loop': 'Combi...  \n",
       "37  {'split': 'train', 'model_in_the_loop': 'Combi...  \n",
       "53  {'split': 'train', 'model_in_the_loop': 'Combi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"adversarial_qa\", 'adversarialQA', split=\"train\").to_pandas()\n",
    "data = data.drop_duplicates(subset=[\"context\"])\n",
    "print(f\"Number of unique contexts: {len(data)}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this dataset for Q&A with ChatGPT, we need to insert the relevant data into our vector datastore - KDB.AI. The only column of data we will insert is the \"context\" column, which we reformat into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Another approach to brain function is to examine the consequences of '\n",
      "         'damage to specific brain areas. Even though it is protected by the '\n",
      "         'skull and meninges, surrounded by cerebrospinal fluid, and isolated '\n",
      "         'from the bloodstream by the blood–brain barrier, the delicate nature '\n",
      "         'of the brain makes it vulnerable to numerous diseases and several '\n",
      "         'types of damage. In humans, the effects of strokes and other types '\n",
      "         'of brain damage have been a key source of information about brain '\n",
      "         'function. Because there is no ability to experimentally control the '\n",
      "         'nature of the damage, however, this information is often difficult '\n",
      "         'to interpret. In animal studies, most commonly involving rats, it is '\n",
      "         'possible to use electrodes or locally injected chemicals to produce '\n",
      "         'precise patterns of damage and then examine the consequences for '\n",
      "         'behavior.'}\n"
     ]
    }
   ],
   "source": [
    "# extract text data from the dataset\n",
    "documents = [\n",
    "    {\n",
    "        'text': r['context'],\n",
    "    } for r in data.to_dict(orient='records')\n",
    "]\n",
    "pprint(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert data to the KDB.AI table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise an HTTP session with the KDB.AI ChatGPT Retrieval Plugin app\n",
    "s = requests.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `/upsert` instruction is used to insert data to the KDB.AI datastore in batches, with each batch being embedded with OpenAI Embedding Model `text-embedding-ada-002` before it is added to the table. We take our contextual data, which has been reformatted into a dictionary, and call `/upsert` on batches of 100 documents at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c4cdf4852344b48df3da65fbb9fe3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batchSize = 100\n",
    "\n",
    "# upsert documents from the dataset in batches\n",
    "for i in tqdm(range(0, len(documents), batchSize)):\n",
    "    i_end = min(len(documents), i+batchSize)\n",
    "    \n",
    "    res = s.post(\n",
    "        \"http://localhost:8000/upsert\",\n",
    "        \n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {BEARER_TOKEN}\"\n",
    "        },\n",
    "        \n",
    "        json = {\n",
    "            \"documents\": documents[i:i_end]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the KDB.AI table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take the list of questions from our dataset and format them into a dictionary. We will randomly choose 5 of these questions to be our queries in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': 'The man who proposed horse powered trams was not associated with what?'}, {'query': 'Cillian Murphy performed?'}, {'query': 'What kind of weather does Cork get?'}, {'query': 'Which of the following is not a song: I Want It All, The Invisible Man, or The Miracle?'}, {'query': 'What is Milton Keynes last name?'}]\n"
     ]
    }
   ],
   "source": [
    "# extract questions and reformat into queries\n",
    "queries = data['question'].tolist()\n",
    "queries = [{'query': queries[i]} for i in range(len(queries))]\n",
    "\n",
    "# choose 5 queries at random \n",
    "i = random.randint(0, len(queries)-5)\n",
    "searchQueries = queries[i:i+5]\n",
    "\n",
    "print(searchQueries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `/query` instruction is used to extract relevant information from the KDB.AI datastore. The queries are embedded into vectors, and a similarity search algorithm is used to calculate its nearest neighbours, representing the most relevant entries in the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# query the vector database\n",
    "results = requests.post(\n",
    "    \"http://localhost:8000/query\",\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {BEARER_TOKEN}\"\n",
    "    },\n",
    "    \n",
    "    json = {\n",
    "        'queries': searchQueries\n",
    "    }\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we iterate through each query and its results, and pass this data to ChatGPT, which uses it to respond to the query with natural language. Here, you can see the three \"nearest neighbour\" pieces of context that ChatGPT uses to form its answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUERY:\n",
      "The man who proposed horse powered trams was not associated with what?\n",
      "\n",
      "CONTEXT:\n",
      "0.31: Within the city there have been two tram networks in operation. A proposal to develop a horse-drawn tram (linking the city's railway termini) was made by American George Francis Train in the 1860s, and implemented in 1872 by the Cork Tramway Company. However, the company ceased trading in 1875 after Cork Corporation refused permission to extend the line, mainly because of objections from cab operators to the type of tracks which – although they were laid to the Irish national railway gauge of 5 ft 3in – protruded from the road surface.\n",
      "0.39: Some street trams (streetcars) used conduit third-rail current collection. The third rail was below street level. The tram picked up the current through a plough (U.S. \"plow\") accessed through a narrow slot in the road. In the United States, much (though not all) of the former streetcar system in Washington, D.C. (discontinued in 1962) was operated in this manner to avoid the unsightly wires and poles associated with electric traction. The same was true with Manhattan's former streetcar system. The evidence of this mode of running can still be seen on the track down the slope on the northern access to the abandoned Kingsway Tramway Subway in central London, United Kingdom, where the slot between the running rails is clearly visible, and on P and Q Streets west of Wisconsin Avenue in the Georgetown neighborhood of Washington DC, where the abandoned tracks have not been paved over.\n",
      "0.42: Steadfast in his promotion of three-phase development, Mikhail Dolivo-Dobrovolsky invented the three-phase cage-rotor induction motor in 1889 and the three-limb transformer in 1890. This type of motor is now used for the vast majority of commercial applications. However, he claimed that Tesla's motor was not practical because of two-phase pulsations, which prompted him to persist in his three-phase work. Although Westinghouse achieved its first practical induction motor in 1892 and developed a line of polyphase 60 hertz induction motors in 1893, these early Westinghouse motors were two-phase motors with wound rotors until B. G. Lamme developed a rotating bar winding rotor. The General Electric Company began developing three-phase induction motors in 1891. By 1896, General Electric and Westinghouse signed a cross-licensing agreement for the bar-winding-rotor design, later called the squirrel-cage rotor.\n",
      "\n",
      "RESPONSE: \n",
      "The man who proposed horse-powered trams, George Francis Train, was not associated with the invention of the three-phase cage-rotor induction motor or the development of electric trams using conduit third-rail current collection.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "QUERY:\n",
      "Cillian Murphy performed?\n",
      "\n",
      "CONTEXT:\n",
      "0.39: The Cork School of Music and the Crawford College of Art and Design provide a throughput of new blood, as do the active theatre components of several courses at University College Cork (UCC). Highlights include: Corcadorca Theatre Company, of which Cillian Murphy was a troupe member prior to Hollywood fame; the Institute for Choreography and Dance, a national contemporary dance resource;[citation needed] the Triskel Arts Centre (capacity c.90), which includes the Triskel Christchurch independent cinema; dance venue the Firkin Crane (capacity c.240); the Cork Academy of Dramatic Art (CADA) and Graffiti Theatre Company; and the Cork Jazz Festival, Cork Film Festival, and Live at the Marquee events. The Everyman Palace Theatre (capacity c.650) and the Granary Theatre (capacity c.150) both play host to dramatic plays throughout the year.\n",
      "0.45: In India, it was reported that the Indian Central Board of Film Certification (CBFC) censored kissing scenes featuring Monica Bellucci, Daniel Craig, and Léa Seydoux. They also muted all profanity. This prompted criticism of the board online, especially on Twitter.\n",
      "0.45: McGuinness Flint, for whom Graham Lyle played the mandolin on their most successful single, When I'm Dead And Gone, is another example. Lyle was also briefly a member of Ronnie Lane's Slim Chance, and played mandolin on their hit How Come. One of the more prominent early mandolin players in popular music was Robin Williamson in The Incredible String Band. Ian Anderson of Jethro Tull is a highly accomplished mandolin player (beautiful track Pussy Willow), as is his guitarist Martin Barre. The popular song Please Please Please Let Me Get What I Want by The Smiths featured a mandolin solo played by Johnny Marr. More recently, the Glasgow-based band Sons and Daughters featured the mandolin, played by Ailidh Lennon, on tracks such as Fight, Start to End, and Medicine. British folk-punk icons the Levellers also regularly use the mandolin in their songs.\n",
      "\n",
      "RESPONSE: \n",
      "Cillian Murphy, before achieving fame in Hollywood, performed as a troupe member with the Corcadorca Theatre Company in Cork, Ireland.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "QUERY:\n",
      "What kind of weather does Cork get?\n",
      "\n",
      "CONTEXT:\n",
      "0.2: The climate of Cork, like the rest of Ireland, is mild and changeable with abundant rainfall and a lack of temperature extremes. Cork lies in plant Hardiness zone 9b. Met Éireann maintains a climatological weather station at Cork Airport, a few kilometres south of the city. It should be noted that the airport is at an altitude of 151 metres (495 ft) and temperatures can often differ by a few degrees between the airport and the city itself. There are also smaller synoptic weather stations at UCC and Clover Hill.\n",
      "0.22: Cork is also a generally foggy city, with an average of 97 days of fog a year, most common during mornings and during winter. Despite this, however, Cork is also one of Ireland's sunniest cities, with an average of 3.9 hours of sunshine every day and only having 67 days where there is no \"recordable sunshine\", mostly during and around winter.\n",
      "0.25: Temperatures below 0 °C (32 °F) or above 25 °C (77 °F) are rare. Cork Airport records an average of 1,227.9 millimetres (4.029 ft) of precipitation annually, most of which is rain. The airport records an average of 7 days of hail and 11 days of snow or sleet a year; though it only records lying snow for 2 days of the year. The low altitude of the city, and moderating influences of the harbour, mean that lying snow very rarely occurs in the city itself. There are on average 204 \"rainy\" days a year (over 0.2 millimetres (0.0079 in) of rainfall), of which there are 73 days with \"heavy rain\" (over 5 millimetres (0.20 in)).\n",
      "\n",
      "RESPONSE: \n",
      "Cork experiences a mild and changeable climate with abundant rainfall and a lack of temperature extremes. The city is generally foggy, with an average of 97 days of fog per year, most common during mornings and winter. Cork is also one of Ireland's sunniest cities, with an average of 3.9 hours of sunshine per day. Temperature extremes below 0 °C (32 °F) or above 25 °C (77 °F) are rare. The city receives an\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "QUERY:\n",
      "Which of the following is not a song: I Want It All, The Invisible Man, or The Miracle?\n",
      "\n",
      "CONTEXT:\n",
      "0.33: After working on various solo projects during 1988 (including Mercury's collaboration with Montserrat Caballé, Barcelona), the band released The Miracle in 1989. The album continued the direction of A Kind of Magic, using a pop-rock sound mixed with a few heavy numbers. It spawned the European hits \"I Want It All\", \"Breakthru\", \"The Invisible Man\", \"Scandal\", and \"The Miracle\". The Miracle also began a change in direction of Queen's songwriting philosophy. Since the band's beginning, nearly all songs had been written by and credited to a single member, with other members adding minimally. With The Miracle, the band's songwriting became more collaborative, and they vowed to credit the final product only to Queen as a group.\n",
      "0.45: Others found renewed success in the singles charts with power ballads, including REO Speedwagon with \"Keep on Loving You\" (1980) and \"Can't Fight This Feeling\" (1984), Journey with \"Don't Stop Believin'\" (1981) and \"Open Arms\" (1982), Foreigner's \"I Want to Know What Love Is\", Scorpions' \"Still Loving You\" (both from 1984), Heart’s \"What About Love\" (1985) and \"These Dreams\" (1986), and Boston's \"Amanda\" (1986).\n",
      "0.47: Certain staples of classical music are often used commercially (either in advertising or in movie soundtracks). In television commercials, several passages have become clichéd, particularly the opening of Richard Strauss' Also sprach Zarathustra (made famous in the film 2001: A Space Odyssey) and the opening section \"O Fortuna\" of Carl Orff's Carmina Burana, often used in the horror genre; other examples include the Dies Irae from the Verdi Requiem, Edvard Grieg's In the Hall of the Mountain King from Peer Gynt, the opening bars of Beethoven's Symphony No. 5, Wagner's Ride of the Valkyries from Die Walküre, Rimsky-Korsakov's Flight of the Bumblebee, and excerpts of Aaron Copland's Rodeo.\n",
      "\n",
      "RESPONSE: \n",
      "Based on my knowledge, \"The Miracle\" is not a song. \"I Want It All\" and \"The Invisible Man\" are both songs by Queen.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "QUERY:\n",
      "What is Milton Keynes last name?\n",
      "\n",
      "CONTEXT:\n",
      "0.46: Other notable Old Etonians include scientists Robert Boyle, John Maynard Smith, J. B. S. Haldane, Stephen Wolfram and the 2012 Nobel Prize in Physiology or Medicine winner, John Gurdon; Beau Brummell; economists John Maynard Keynes and Richard Layard; Antarctic explorer Lawrence Oates; politician Alan Clark; entrepreneur, charity organiser and partner of Adele, Simon Konecki; cricket commentator Henry Blofeld; explorer Sir Ranulph Fiennes; adventurer Bear Grylls; composers Thomas Arne, George Butterworth, Roger Quilter, Frederick Septimus Kelly, Donald Tovey, Thomas Dunhill, Lord Berners, Victor Hely-Hutchinson, and Peter Warlock (Philip Heseltine); Hubert Parry, who wrote the song Jerusalem and the coronation anthem I was glad; and musicians Frank Turner and Humphrey Lyttelton.\n",
      "0.48: In June 1990, The Times ceased its policy of using courtesy titles (\"Mr\", \"Mrs\", or \"Miss\" prefixes) for living persons before full names on first reference, but it continues to use them before surnames on subsequent references. The more formal style is now confined to the \"Court and Social\" page, though \"Ms\" is now acceptable in that section, as well as before surnames in news sections.\n",
      "0.49: In 1762, George III acquired Buckingham House and it was enlarged over the next 75 years. During the 18th century, London was dogged by crime, and the Bow Street Runners were established in 1750 as a professional police force. In total, more than 200 offences were punishable by death, including petty theft. Most children born in the city died before reaching their third birthday. The coffeehouse became a popular place to debate ideas, with growing literacy and the development of the printing press making news widely available; and Fleet Street became the centre of the British press.\n",
      "\n",
      "RESPONSE: \n",
      "Based on my knowledge, Milton Keynes does not have a last name. However, if you are referring to the town of Milton Keynes in Buckinghamshire, England, it is named after the existing villages of Milton Keynes, Bletchley, and Wolverton.\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# iterate through each set of queries/results\n",
    "for query_response in results.json()['results']:\n",
    "    query = query_response['query']\n",
    "    answers = []\n",
    "    scores = []\n",
    "    \n",
    "    # extract answers and scores from each result\n",
    "    for result in query_response['results']:\n",
    "        \n",
    "        # answer = textual information related to the query\n",
    "        answers.append(result['text'])\n",
    "        \n",
    "        # score = distance between the query vector and the answer vector (smaller=better!)\n",
    "        scores.append(round(result['score'], 2))\n",
    "    \n",
    "    # print the query\n",
    "    print(\"\\nQUERY:\\n\"+query)\n",
    "    \n",
    "    # print the query responses, and their scores\n",
    "    print(\"\\nCONTEXT:\\n\"+\"\\n\".join([f\"{s}: {a}\" for a, s in zip(answers, scores)])+\"\\n\")\n",
    "    \n",
    "    # format the query and its answers into GPT messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"You are a helpful assistant with the following knowledge: {answers}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Using your knowledge, answer this query: {query}\"}\n",
    "    ]\n",
    "    \n",
    "    # send the messages to a GPT model\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=messages,\n",
    "      max_tokens=100,\n",
    "      n=1,\n",
    "      stop=None,            \n",
    "    )\n",
    "\n",
    "    # extract the generated response from the API response\n",
    "    generated_response =response['choices'][0]['message']['content']\n",
    "    \n",
    "    # Print the generated response\n",
    "    print(f\"RESPONSE: \\n{generated_response}\\n\")\n",
    "    print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the KDB.AI table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete the KDB.AI table, run the code cell below. Once this is done, the ChatGPT Retrieval Plugin app will need to be restarted to create another table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One would need to restart the KDB.AI ChatGPT Retrieval Plugin server app\n",
    "## after this, to recreate the table\n",
    "res = requests.delete(\n",
    "    \"http://localhost:8000/delete\",\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {BEARER_TOKEN}\"\n",
    "    }, \n",
    "    json = {\n",
    "        \"delete_all\": True\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
